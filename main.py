from fastapi import FastAPI, Request, Form, UploadFile, Body
from fastapi.responses import HTMLResponse, RedirectResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
import os
from dotenv import load_dotenv
import asyncpg
import json
from datetime import datetime
import openai
import base64
from glob import glob
import aiohttp
from utils import (
    log_message, download_image_from_url, encode_image_base64, clean_json_response, extract_estimate_from_response, analyze_image_openai_json,
    get_pg_pool, get_next_image_to_label, get_candidates_info, get_batch_images_for_label
)
import decimal

def convert_decimal(obj):
    if isinstance(obj, list):
        return [convert_decimal(i) for i in obj]
    if isinstance(obj, dict):
        return {k: convert_decimal(v) for k, v in obj.items()}
    if isinstance(obj, decimal.Decimal):
        return float(obj)
    return obj

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Jinja2 templates
templates = Jinja2Templates(directory="templates")

# Load environment variables from .env
load_dotenv()

DB_HOST = os.getenv("POSTGRES_HOST")
DB_PORT = int(os.getenv("POSTGRES_PORT"))
DB_NAME = os.getenv("POSTGRES_DB")
DB_USER = os.getenv("POSTGRES_USER")
DB_PASSWORD = os.getenv("POSTGRES_PASSWORD")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not all([DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD, OPENAI_API_KEY]):
    raise RuntimeError("Missing one or more required environment variables: POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD, OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

PROMPT = '''B·∫°n l√† m·ªôt chuy√™n gia n·ªôi th·∫•t v√† th·ªã gi√°c m√°y t√≠nh.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† quan s√°t h√¨nh ·∫£nh n·ªôi th·∫•t ƒë·∫ßu v√†o, v√† g√°n nh√£n s·∫£n ph·∫©m theo 7 nh√≥m thu·ªôc t√≠nh chi ti·∫øt c√πng v·ªõi ch·ªâ s·ªë tin c·∫≠y (confidence score) t·ª´ 0 ƒë·∫øn 1.

üéØ M·ª•c ti√™u:
Tr·∫£ v·ªÅ d·ªØ li·ªáu c√≥ c·∫•u tr√∫c JSON v·ªõi c√°c tr∆∞·ªùng sau:
{
  "loai_san_pham": "...",
  "chat_lieu": "...",
  "vi_tri": "...",
  "mau_sac": "...",
  "phong_cach_thiet_ke": "...",
  "kieu_dang": "...",
  "chuc_nang_phu": "...",
  "dac_diem_nhan_dang": "...",
  "chi_so_tin_cay": 0.0
}

Trong ƒë√≥:
- loai_san_pham: V√≠ d·ª•: gh·∫ø, gi∆∞·ªùng, ƒë√®n, t·ªß, ch·∫≠u c√¢y, sofa, r√®m c·ª≠a...
- chat_lieu: V√≠ d·ª•: g·ªó, kim lo·∫°i, v·∫£i, n·ªâ, da, k√≠nh, m√¢y ƒëan...
- vi_tri: 1 trong 3 v·ªã tr√≠ sau: "Tr√™n t∆∞·ªùng", "Tr√™n tr·∫ßn nh√†", "Tr√™n s√†n". Ch√∫ th√≠ch: tr√™n s√†n l√† bao g·ªìm ƒë·∫∑t tr·ª±c ti·∫øp tr√™n s√†n ho·∫∑c ƒë·∫∑t tr√™n c√°c v·∫≠t d·ª•ng tr√™n s√†n vd nh∆∞ b√†n, k·ªá, t·ªß
- mau_sac: M√†u ch·ªß ƒë·∫°o quan s√°t ƒë∆∞·ª£c (v√≠ d·ª•: tr·∫Øng ng√†, be, ƒëen, g·ªó s√°ng...)
- phong_cach_thiet_ke: V√≠ d·ª•: hi·ªán ƒë·∫°i, t·ªëi gi·∫£n, B·∫Øc √Çu, retro, c√¥ng nghi·ªáp, c·ªï ƒëi·ªÉn...
- kieu_dang: M√¥ t·∫£ c·∫•u tr√∫c t·ªïng th·ªÉ: kh·ªëi h·ªôp, tr·ª• ƒë·ª©ng, cong m·ªÅm, ch√¢n th·∫•p, l∆∞ng cao...
- chuc_nang_phu: V√≠ d·ª•: g·∫•p g·ªçn, c√≥ ngƒÉn k√©o, trang tr√≠, chi·∫øu s√°ng, d√πng ngo√†i tr·ªùi...
- dac_diem_nhan_dang: M√¥ t·∫£ ƒëi·ªÉm ƒë·∫∑c tr∆∞ng gi√∫p ph√¢n bi·ªát v·ªõi s·∫£n ph·∫©m kh√°c
- chi_so_tin_cay: M·ªôt s·ªë trong kho·∫£ng 0.00 ‚Äì 1.00, th·ªÉ hi·ªán m·ª©c ƒë·ªô ch·∫Øc ch·∫Øn v√†o vi·ªác g√°n nh√£n d·ª±a tr√™n ·∫£nh

‚ö†Ô∏è L∆∞u √Ω khi g√°n nh√£n:
N·∫øu ·∫£nh kh√¥ng ƒë·ªß th√¥ng tin cho m·ªôt tr∆∞·ªùng n√†o ƒë√≥, h√£y ghi r√µ l√† "Kh√¥ng r√µ" ho·∫∑c "Kh√¥ng x√°c ƒë·ªãnh".
ƒê·∫£m b·∫£o t·∫•t c·∫£ m√¥ t·∫£ kh√°ch quan, ng·∫Øn g·ªçn, d·ªÖ d√πng cho h·ªá th·ªëng t√¨m ki·∫øm ho·∫∑c l·ªçc ·∫£nh.
Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON, kh√¥ng gi·∫£i th√≠ch, kh√¥ng th√™m vƒÉn b·∫£n ngo√†i JSON.
üì• ƒê·∫ßu v√†o:
M·ªôt ·∫£nh n·ªôi th·∫•t (b·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c ·∫£nh s·∫£n ph·∫©m k√®m theo).
'''

IMAGES_DIR = "images"

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request, edit_id: int = None):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    if edit_id:
        async with pool.acquire() as conn:
            row = await conn.fetchrow('SELECT * FROM abt_image_to_products_1688 WHERE id = $1', edit_id)
            if row:
                row = dict(row)
            else:
                row = None
    else:
        row = await get_next_image_to_label(pool)
    if not row:
        return templates.TemplateResponse("index.html", {"request": request, "done": True})
    image_url = row.get("image_url")
    abt_label = row.get("abt_label")
    abt_label_fields = None
    if abt_label:
        try:
            abt_label_fields = json.loads(abt_label)
        except Exception:
            abt_label_fields = None
    candidates_json = row.get("products_1688_filtered")
    candidates = []
    offer_ids = []
    if candidates_json:
        try:
            data = json.loads(candidates_json)
            candidates = data.get("candidates", [])
            offer_ids = [c.get("offer_id") for c in candidates if c.get("offer_id")]
        except Exception:
            pass
    # L·∫•y th√™m tr∆∞·ªùng price v√† subject_trans
    async def get_candidates_info_with_price(pool, offer_ids):
        if not offer_ids:
            return []
        async with pool.acquire() as conn:
            rows = await conn.fetch(
                'SELECT offer_id, image_url, subject_trans, price FROM abt_products_1688 WHERE offer_id = ANY($1)', offer_ids
            )
            return [dict(row) for row in rows]
    candidates_info = await get_candidates_info_with_price(pool, offer_ids)
    info_map = {c["offer_id"]: c for c in candidates_info}
    candidates_full = [info_map.get(oid) for oid in offer_ids if oid in info_map]
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "image_url": image_url,
            "candidates": candidates_full,
            "row_id": row.get("id"),
            "done": False,
            "abt_label_fields": abt_label_fields
        }
    )

@app.post("/submit")
async def submit_best_match(request: Request, row_id: int = Form(...), selected_offer_id: str = Form(...), user: str = Form(...), elapsed_time: int = Form(...)):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    offer_id = selected_offer_id if selected_offer_id else None
    best_match = {
        "offer_id": offer_id,
        "timestamp": datetime.now().isoformat(),
        "review_status": 0,
        "user": user,
        "elapsed_time": elapsed_time
    }
    async with pool.acquire() as conn:
        await conn.execute(
            'UPDATE abt_image_to_products_1688 SET best_match = $1 WHERE id = $2',
            json.dumps(best_match, ensure_ascii=False),
            row_id
        )
    return RedirectResponse(url="/", status_code=303)

@app.get("/analyze_image", response_class=HTMLResponse)
async def analyze_image_form(request: Request):
    return templates.TemplateResponse("analyze_image.html", {"request": request, "result": None, "batch_size": 5})

@app.post("/analyze_image", response_class=HTMLResponse)
async def analyze_image_batch(request: Request, batch_size: int = Form(...)):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    rows = await get_batch_images_for_label(pool, batch_size)
    logs = []
    for row in rows:
        image_url = row.get("image_url")
        row_id = row.get("id")
        if not image_url or not row_id:
            log_message(f"B·ªè qua d√≤ng thi·∫øu th√¥ng tin id={row_id}", logs)
            continue
        from urllib.parse import urlparse, unquote
        parsed_url = urlparse(image_url)
        path = parsed_url.path
        img_name = os.path.basename(path)
        local_path = os.path.join(IMAGES_DIR, f"dbimg_{row_id}_{img_name}")
        if not os.path.exists(local_path):
            ok = await download_image_from_url(image_url, local_path)
            if not ok:
                log_message(f"L·ªói t·∫£i ·∫£nh cho id={row_id}", logs)
                continue
        try:
            abt_label, abt_label_cost = await analyze_image_openai_json(local_path, PROMPT, openai)
            async with pool.acquire() as conn:
                await conn.execute(
                    'UPDATE abt_image_to_products_1688 SET abt_label = $1, abt_label_cost = $2 WHERE id = $3',
                    abt_label,
                    abt_label_cost,
                    row_id
                )
            log_message(f"ƒê√£ x·ª≠ l√Ω id={row_id}", logs)
        except Exception as e:
            log_message(f"L·ªói AI cho id={row_id}: {e}", logs)
    return templates.TemplateResponse("analyze_image.html", {"request": request, "result": '\n'.join(logs), "batch_size": batch_size})

@app.get("/api/get_batch_images")
async def api_get_batch_images(batch_size: int = 5):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    rows = await get_batch_images_for_label(pool, batch_size)
    # Tr·∫£ v·ªÅ id, image_url cho client
    return JSONResponse([{"id": row["id"], "image_url": row["image_url"]} for row in rows])

@app.post("/api/analyze_image_one")
async def api_analyze_image_one(data: dict = Body(...)):
    row_id = data.get("id")
    image_url = data.get("image_url")
    if not row_id or not image_url:
        return JSONResponse({"success": False, "msg": "Thi·∫øu id ho·∫∑c image_url"})
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    from urllib.parse import urlparse
    parsed_url = urlparse(image_url)
    path = parsed_url.path
    img_name = os.path.basename(path)
    local_path = os.path.join(IMAGES_DIR, f"dbimg_{row_id}_{img_name}")
    if not os.path.exists(local_path):
        ok = await download_image_from_url(image_url, local_path)
        if not ok:
            return JSONResponse({"success": False, "msg": f"L·ªói t·∫£i ·∫£nh cho id={row_id}"})
    try:
        abt_label, abt_label_cost = await analyze_image_openai_json(local_path, PROMPT, openai)
        async with pool.acquire() as conn:
            await conn.execute(
                'UPDATE abt_image_to_products_1688 SET abt_label = $1, abt_label_cost = $2, updated_at = NOW() WHERE id = $3',
                abt_label,
                abt_label_cost,
                row_id
            )
        abt_label_after = abt_label
        return JSONResponse({
            "success": True,
            "msg": f"ƒê√£ x·ª≠ l√Ω id={row_id}",
            "abt_label_cost": abt_label_cost,
            "abt_label_after": abt_label_after
        })
    except Exception as e:
        return JSONResponse({"success": False, "msg": f"L·ªói AI cho id={row_id}: {e}", "abt_label_cost": None, "abt_label_after": None})

@app.get("/api/analyze_stats")
async def api_analyze_stats():
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    async with pool.acquire() as conn:
        # L·∫•y t·ªïng s·ªë item
        total = await conn.fetchval("SELECT COUNT(*) FROM abt_image_to_products_1688")
        # L·∫•y t·ªïng s·ªë item ƒë√£ ph√¢n t√≠ch (c√≥ abt_label)
        analyzed = await conn.fetchval("SELECT COUNT(*) FROM abt_image_to_products_1688 WHERE abt_label IS NOT NULL")
        # L·∫•y th·ªëng k√™ theo ng√†y (d·ª±a v√†o updated_at ho·∫∑c timestamp trong abt_label_cost n·∫øu c√≥)
        rows = await conn.fetch('''
            SELECT id, abt_label, abt_label_cost, updated_at
            FROM abt_image_to_products_1688
            WHERE abt_label IS NOT NULL
        ''')
        from collections import defaultdict
        import datetime
        import json as pyjson
        day_stats = defaultdict(lambda: {"count": 0, "confidence": [], "date": None})
        for row in rows:
            # L·∫•y ng√†y t·ª´ updated_at ho·∫∑c timestamp trong abt_label_cost
            date_str = None
            if row["abt_label_cost"]:
                try:
                    cost = pyjson.loads(row["abt_label_cost"])
                    ts = cost.get("timestamp")
                    if ts:
                        date_str = ts[:10]
                except Exception:
                    pass
            if not date_str and row.get("updated_at"):
                date_str = str(row["updated_at"])[:10]
            if not date_str:
                date_str = "unknown"
            # L·∫•y confidence score
            conf = None
            if row["abt_label"]:
                try:
                    label = pyjson.loads(row["abt_label"])
                    conf = label.get("chi_so_tin_cay")
                except Exception:
                    pass
            day_stats[date_str]["count"] += 1
            if conf is not None:
                try:
                    day_stats[date_str]["confidence"].append(float(conf))
                except Exception:
                    pass
            day_stats[date_str]["date"] = date_str
        # Chuy·ªÉn sang list, sort theo ng√†y
        stats_list = sorted(day_stats.values(), key=lambda x: x["date"])
        for s in stats_list:
            if s["confidence"]:
                s["avg_confidence"] = sum(s["confidence"]) / len(s["confidence"])
            else:
                s["avg_confidence"] = None
        return JSONResponse({
            "total": total,
            "analyzed": analyzed,
            "pending": total - analyzed,
            "stats": stats_list
        })

@app.get("/api/filter_history")
async def api_filter_history(user: str = None):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    async with pool.acquire() as conn:
        import json as pyjson
        if user:
            query = '''
                SELECT id, image_url, best_match, products_1688_filtered
                FROM abt_image_to_products_1688
                WHERE best_match IS NOT NULL AND best_match->>'user' = $1
                ORDER BY id DESC
                LIMIT 500
            '''
            rows = await conn.fetch(query, user)
        else:
            query = '''
                SELECT id, image_url, best_match, products_1688_filtered
                FROM abt_image_to_products_1688
                WHERE best_match IS NOT NULL
                ORDER BY id DESC
                LIMIT 500
            '''
            rows = await conn.fetch(query)
        result = []
        for row in rows:
            best_match = None
            try:
                best_match = pyjson.loads(row["best_match"])
            except Exception:
                continue
            offer_id = best_match.get("offer_id")
            user_val = best_match.get("user")
            elapsed_time = best_match.get("elapsed_time")
            timestamp = best_match.get("timestamp")
            subject_trans = offer_id
            candidate_img = None
            if row["products_1688_filtered"]:
                try:
                    candidates = pyjson.loads(row["products_1688_filtered"]).get("candidates", [])
                    for c in candidates:
                        if c.get("offer_id") == offer_id:
                            subject_trans = c.get("subject_trans") or offer_id
                            break
                except Exception:
                    pass
            candidate_img = None
            if offer_id:
                cand_row = await conn.fetchrow('SELECT image_url FROM abt_products_1688 WHERE offer_id = $1', offer_id)
                if cand_row:
                    candidate_img = cand_row["image_url"]
            result.append({
                "id": row["id"],
                "image_url": row["image_url"],
                "candidate_img": candidate_img,
                "subject_trans": subject_trans,
                "user": user_val,
                "elapsed_time": elapsed_time,
                "timestamp": timestamp
            })
        return JSONResponse(result)

@app.get("/filter_history", response_class=HTMLResponse)
async def filter_history_page(request: Request):
    return templates.TemplateResponse("filter_history.html", {"request": request})

@app.get("/api/filter_history_stats")
async def api_filter_history_stats():
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    async with pool.acquire() as conn:
        rows = await conn.fetch('''
            SELECT best_match FROM abt_image_to_products_1688 WHERE best_match IS NOT NULL
        ''')
        import json as pyjson
        from collections import defaultdict
        # Th·ªëng k√™ theo ng√†y
        day_stats = defaultdict(lambda: {"count": 0, "sum_time": 0, "users": defaultdict(lambda: {"count": 0, "sum_time": 0})})
        # Th·ªëng k√™ theo user
        user_stats = defaultdict(lambda: {"count": 0, "sum_time": 0})
        for row in rows:
            try:
                bm = pyjson.loads(row["best_match"])
                ts = bm.get("timestamp", "")[:10]
                user = bm.get("user", "?")
                elapsed = bm.get("elapsed_time")
                if elapsed is not None:
                    elapsed = int(elapsed)
                else:
                    elapsed = 0
                # Theo ng√†y
                day_stats[ts]["count"] += 1
                day_stats[ts]["sum_time"] += elapsed
                day_stats[ts]["users"][user]["count"] += 1
                day_stats[ts]["users"][user]["sum_time"] += elapsed
                # Theo user
                user_stats[user]["count"] += 1
                user_stats[user]["sum_time"] += elapsed
            except Exception:
                pass
        # Chu·∫©n b·ªã d·ªØ li·ªáu tr·∫£ v·ªÅ
        stats_by_day = []
        for day, v in sorted(day_stats.items()):
            avg_time = v["sum_time"] / v["count"] if v["count"] else 0
            stats_by_day.append({
                "date": day,
                "count": v["count"],
                "sum_time": v["sum_time"],
                "avg_time": avg_time
            })
        stats_by_user = []
        for user, v in sorted(user_stats.items()):
            avg_time = v["sum_time"] / v["count"] if v["count"] else 0
            stats_by_user.append({
                "user": user,
                "count": v["count"],
                "sum_time": v["sum_time"],
                "avg_time": avg_time
            })
        return JSONResponse({
            "stats_by_day": stats_by_day,
            "stats_by_user": stats_by_user
        })

@app.get("/api/filter_item")
async def api_filter_item(id: int):
    pool = await get_pg_pool(DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME)
    async with pool.acquire() as conn:
        row = await conn.fetchrow('SELECT * FROM abt_image_to_products_1688 WHERE id = $1', id)
        if not row:
            return JSONResponse({"error": "Not found"}, status_code=404)
        row = dict(row)
        import json as pyjson
        abt_label = row.get("abt_label")
        abt_label_fields = None
        if abt_label:
            try:
                abt_label_fields = pyjson.loads(abt_label)
            except Exception:
                abt_label_fields = None
        candidates_json = row.get("products_1688_filtered")
        candidates = []
        offer_ids = []
        if candidates_json:
            try:
                data = pyjson.loads(candidates_json)
                candidates = data.get("candidates", [])
                offer_ids = [c.get("offer_id") for c in candidates if c.get("offer_id")]
            except Exception:
                pass
        # L·∫•y th√™m tr∆∞·ªùng price v√† subject_trans
        async def get_candidates_info_with_price(pool, offer_ids):
            if not offer_ids:
                return []
            async with pool.acquire() as conn:
                rows = await conn.fetch(
                    'SELECT offer_id, image_url, subject_trans, price FROM abt_products_1688 WHERE offer_id = ANY($1)', offer_ids
                )
                return [dict(row) for row in rows]
        candidates_info = await get_candidates_info_with_price(pool, offer_ids)
        info_map = {c["offer_id"]: c for c in candidates_info}
        candidates_full = [info_map.get(oid) for oid in offer_ids if oid in info_map]
        return JSONResponse({
            "id": row.get("id"),
            "image_url": row.get("image_url"),
            "candidates": convert_decimal(candidates_full),
            "abt_label_fields": abt_label_fields
        }) 